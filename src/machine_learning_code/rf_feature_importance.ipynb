{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature  Importance  Rank\n",
      "0     Number_of_punctuation    0.124580     1\n",
      "1          Redundancy_score    0.076288     2\n",
      "2           sentiment_score    0.069163     3\n",
      "3           Number_of_words    0.068938     4\n",
      "4         Readability_score    0.063766     5\n",
      "5            positive_score    0.055160     6\n",
      "6         Lexical_diversity    0.053936     7\n",
      "7   Average_sentence_length    0.053788     8\n",
      "8       Average_word_length    0.051664     9\n",
      "9             neutral_score    0.050840    10\n",
      "10           Number_of_caps    0.041163    11\n",
      "11          Number_of_nouns    0.039119    12\n",
      "12      Number_of_sentences    0.031647    13\n",
      "13           negative_score    0.028660    14\n",
      "14          Number_of_verbs    0.027262    15\n",
      "15      intensity_modifiers    0.025778    16\n",
      "16     Number_of_adjectives    0.025616    17\n",
      "17        Number_of_adverbs    0.025168    18\n",
      "18            neutral_words    0.023781    19\n",
      "19        polarity_shifters    0.023024    20\n",
      "20           positive_words    0.014965    21\n",
      "21                negations    0.013438    22\n",
      "22           negative_words    0.010272    23\n",
      "23                emoticons    0.001986    24\n"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "os.chdir('C:/Users/jesse/OneDrive/Documenten/Thesis/amazon_code/dataframes_done')\n",
    "\n",
    "# Read tJSON file\n",
    "df = pd.read_json('VADER_df_norm.json', orient='records')\n",
    "\n",
    "# Train and test set\n",
    "X = df.drop(['Label'], axis=1)\n",
    "y = df['Label']\n",
    "train_size = 0.8\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=42)\n",
    "\n",
    "# Train\n",
    "regressor = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Feature Importance\n",
    "importance = regressor.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\"Feature\": X.columns, \"Importance\": importance})\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "feature_importance_df = feature_importance_df.reset_index(drop=True)\n",
    "feature_importance_df[\"Rank\"] = feature_importance_df.index + 1\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Feature  Importance  Rank\n",
      "0        Number_of_punctuation    0.122764     1\n",
      "1             Redundancy_score    0.069734     2\n",
      "2              Sentiment_score    0.068750     3\n",
      "3              Number_of_words    0.062212     4\n",
      "4            Readability_score    0.055802     5\n",
      "5             Review_intensity    0.052058     6\n",
      "6            Lexical_diversity    0.050221     7\n",
      "7      Average_sentence_length    0.050123     8\n",
      "8          Average_word_length    0.049989     9\n",
      "9              Number_of_nouns    0.040265    10\n",
      "10              Number_of_caps    0.039683    11\n",
      "11  Number_of_objective words:    0.031375    12\n",
      "12         Number_of_sentences    0.029564    13\n",
      "13            Review_ambiguity    0.027420    14\n",
      "14           Number_of_adverbs    0.023549    15\n",
      "15        Number_of_adjectives    0.022292    16\n",
      "16             Number_of_verbs    0.021755    17\n",
      "17   Number_of_positive words:    0.021120    18\n",
      "18   Number_of_negative words:    0.019277    19\n",
      "19                     pos_125    0.015733    20\n",
      "20                       pos_5    0.015365    21\n",
      "21                     pos_625    0.013680    22\n",
      "22                     neg_125    0.013292    23\n",
      "23                      pos_25    0.012653    24\n",
      "24                      neg_25    0.012402    25\n",
      "25                       neg_5    0.011024    26\n",
      "26                     neg_625    0.009905    27\n",
      "27                     pos_375    0.009747    28\n",
      "28                     neg_375    0.008283    29\n",
      "29                      neg_75    0.006003    30\n",
      "30                     pos_875    0.005659    31\n",
      "31                      pos_75    0.004797    32\n",
      "32                     neg_875    0.003342    33\n",
      "33                       neg_1    0.000160    34\n",
      "34                       pos_1    0.000000    35\n"
     ]
    }
   ],
   "source": [
    "# Set working directory\n",
    "os.chdir('C:/Users/jesse/OneDrive/Documenten/Thesis/amazon_code/dataframes_done')\n",
    "\n",
    "# Read tJSON file\n",
    "df = pd.read_json('senti_df_norm.json', orient='records')\n",
    "\n",
    "# Train and test set\n",
    "X = df.drop(['Label'], axis=1)\n",
    "y = df['Label']\n",
    "train_size = 0.8\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=train_size, random_state=42)\n",
    "\n",
    "# Train\n",
    "regressor = RandomForestRegressor(n_estimators=100, max_depth=10)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# Feature Importance\n",
    "importance = regressor.feature_importances_\n",
    "feature_importance_df = pd.DataFrame({\"Feature\": X.columns, \"Importance\": importance})\n",
    "feature_importance_df = feature_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "feature_importance_df = feature_importance_df.reset_index(drop=True)\n",
    "feature_importance_df[\"Rank\"] = feature_importance_df.index + 1\n",
    "print(feature_importance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
